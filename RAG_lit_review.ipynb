{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RAG System Overview for Jamming Source Localization Research\n",
        "\n",
        "\n",
        "The code below implements a Retrieval-Augmented Generation (RAG) system, designed to support literature review tasks by allowing access to documents published after the model’s training data cutoff, as well as documents that require special access online (e.g., documents behind paywalls or requiring credentials). This system enhances the access to contextual information from diverse documents, significantly boosting the accuracy and quality of responses from language models.\n",
        "\n",
        "In my application, I utilize this system to process over 30 research papers on jamming source localization.\n",
        "\n",
        "### Purpose of the RAG System\n",
        "\n",
        "The main function of this RAG system is to aid in the review and analysis of research papers, particularly those concerning jamming source localization, though it can be adapted to other fields as well. Its objective is to efficiently gather and synthesize relevant information, thereby supporting researchers and practitioners in staying 'in-the-know' of the newest developments and techniques in this specialized area of study.\n",
        "\n",
        "Sure, here's the updated description with the components listed in the order that they appear in the code:\n",
        "\n",
        "### Core Components of the RAG System\n",
        "\n",
        "- **OpenAI Embeddings (LLM)**: Utilizes OpenAI's embeddings, which serve as the foundation for generating context-aware text and creating semantic embeddings. These embeddings are crucial for retrieving the most relevant information related to user queries.\n",
        "\n",
        "- **FAISS Vector Store**: The Facebook AI Similarity Search (FAISS) Vector Store is critical for storing and swiftly retrieving document embeddings, thus allowing the system to find and pull the most pertinent documents based on content similarity to user queries.\n",
        "\n",
        "- **Retriever**: Functions like the system's search engine, querying the FAISS Vector Store to fetch documents that match the user's input, ensuring the responses are supported by the most relevant data.\n",
        "\n",
        "- **Cache-Backed Embedder**: Converts text data into vector format before embedding it into the vector store, making it comprehensible and retrievable by the system for future queries.\n",
        "\n",
        "- **Document Processing Pipeline**: Handles the processing of documents with several key subcomponents:\n",
        "  - **Document Loader**: Loads and preprocesses the research papers, making them ready for embedding and retrieval.\n",
        "  - **Text Splitter (Document Chunker)**: Splits extensive research papers into smaller, more manageable chunks, which are easier to process for embedding and retrieval.\n",
        "  - **SimpleDocument Class**: Organizes text chunks along with their metadata, assigning a unique key to each for efficient management and retrieval.\n",
        "\n",
        "- **LLM Setup (ChatOpenAI)**: Utilizes the ChatOpenAI model, specifically gpt-3.5-turbo, set to a temperature of 0.2 and capable of handling up to 4096 tokens. This model enhances the generation of contextual responses based on the retrieved documents.\n",
        "\n",
        "- **Conversational Retrieval Chain**: Integrates the LLM, memory, and retriever with callback functions, enhancing the dynamic interaction between the user and the retrieval system. This chain also returns source documents for transparency and deeper analysis.\n",
        "  - **Memory Management**: Features a Conversation Buffer Memory that tracks the history of user queries and responses, thereby optimizing the contextual relevance of each interaction.\n",
        "  - **Output Handler**: Employs a StdOutCallbackHandler to directly print responses, facilitating immediate feedback from the system.\n",
        "\n",
        "### Text Splitters Experimentation\n",
        "The project experiments with two types of text splitters—RecursiveCharacterTextSplitter and CharacterTextSplitter—to identify the best approach for dividing large text documents into manageable chunks. Through a series of tests chunk_overlap, each splitter's performance is evaluated based on metrics like average chunk size (set to average page content length), number of chunks, and evaluation time. This process aims to find the optimal balance between efficiency (minimizing computational overhead) and granularity (ensuring detailed segmentation), enhancing both the system's performance and retrieval accuracy.\n",
        "\n",
        "A higher number of chunks means the text is split into finer, more detailed parts. This can be beneficial for analyzing specific sections in depth but might increase processing time and complexity. Larger chunks reduce the processing load as there are fewer pieces to manage and index, which can speed up retrieval tasks. However, too large chunks might miss finer details.\n",
        "\n",
        "We want to achieve:   \n",
        "- Adequate granularity without producing an excessive number of small chunks that could slow down the system.\n",
        "- Manageable chunk sizes that are not too large, maintaining necessary detail for effective analysis and retrieval.\n",
        "\n",
        "### System Interaction and Workflow\n",
        "\n",
        "The workflow of the RAG system is tailored to enhance research on jamming source localization by following these steps:\n",
        "\n",
        "1. **Query Processing**: The system begins by taking a user query related to jamming source localization and converting it into an embedding.\n",
        "2. **Document Retrieval**: It then retrieves documents that closely match the query's embedding from the vector store, focusing on those most relevant to jamming source localization.\n",
        "3. **Response Generation**: Leveraging the retrieved documents, the system generates detailed responses that are informed by the latest research findings, helping users synthesize current trends and results in the field.\n",
        "\n",
        "\n",
        "This RAG system streamlines the accessibility to state-of-the-art research in in jamming source localization or any other relevant field being researched. By simply replacing the research papers in the relevant directory with the specific research topic papers, the literature review stage can be accelerated and the concise information required can be accesses in a much more flexible way."
      ],
      "metadata": {
        "id": "DaHqz2gNpVBj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FCz0cvWF_wbA"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install langchain langchain-community langchain-openai openai faiss-cpu tiktoken pdfplumber ipywidgets  > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import openai\n",
        "import hashlib\n",
        "import textwrap\n",
        "import warnings\n",
        "import pdfplumber\n",
        "import contextlib\n",
        "import regex as re\n",
        "from io import StringIO\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "from langchain.schema import Document\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "s5cTv6B3ZIvE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gnISdj8lMqKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d394c5-11a8-4632-9037-be45595526a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your OpenAI API key: ··········\n",
            "API key is set and valid.\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "# Input cell for setting API key (input is hidden)\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key: \").strip()\n",
        "\n",
        "# Function to validate the API key\n",
        "def validate_api_key(api_key):\n",
        "    if not api_key:\n",
        "        raise ValueError(\"The API key is not set. Please set the OPENAI_API_KEY environment variable.\")\n",
        "    elif api_key == \"YOUR_API_KEY_HERE\": # if required set specific API key here\n",
        "        raise ValueError(\"The provided API key is a placeholder. Please provide a valid OpenAI API key.\")\n",
        "\n",
        "# Validate the API key\n",
        "validate_api_key(os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "print(\"API key is set and valid.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "papers_directory = '/content/drive/My Drive/genai_project/papers' # content in papers directory is in .pdf format, papers can be replaced with any relevant content in .txt or .pdf format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXi9Zo2cZnN-",
        "outputId": "12cea5bd-a358-4058-86ff-b936f58600f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert PDF research papers to text\n",
        "def convert_pdfs_to_text(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(directory, filename)\n",
        "            text_path = os.path.join(directory, filename.replace('.pdf', '.txt'))\n",
        "            if not os.path.exists(text_path):  # Check if the text file already exists\n",
        "                with pdfplumber.open(pdf_path) as pdf:\n",
        "                    full_text = []\n",
        "                    for page in pdf.pages:\n",
        "                        page_text = page.extract_text()\n",
        "                        if page_text:\n",
        "                            full_text.append(page_text)\n",
        "                    full_text = \"\\n\".join(full_text)\n",
        "                with open(text_path, 'w', encoding='utf-8') as text_file:\n",
        "                    text_file.write(full_text)\n",
        "                    print(f\"Converted {filename} to text.\")\n",
        "\n",
        "convert_pdfs_to_text(papers_directory)"
      ],
      "metadata": {
        "id": "GsCIENesQLnW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate splitters\n",
        "def evaluate_splitter(documents, splitter, metric='avg_chunk_size'):\n",
        "    start_time = time.time()\n",
        "    chunks = [Document(page_content=chunk) for document in documents for chunk in splitter.split_text(document.page_content)]\n",
        "    end_time = time.time()\n",
        "    num_chunks = len(chunks)\n",
        "    avg_chunk_size = sum(len(chunk.page_content) for chunk in chunks) / num_chunks if num_chunks else 0\n",
        "    eval_time = end_time - start_time\n",
        "\n",
        "    if metric == 'num_chunks':\n",
        "        return num_chunks\n",
        "    elif metric == 'eval_time':\n",
        "        return eval_time\n",
        "    else:\n",
        "        return avg_chunk_size\n",
        "\n",
        "# Define text splitters and chunk_overlap values to test\n",
        "chunk_overlap_values = [0, 10, 25, 50, 100]  # added 0 to experiment with\n",
        "splitters = {\n",
        "    \"RecursiveCharacterTextSplitter\": RecursiveCharacterTextSplitter,\n",
        "    \"CharacterTextSplitter\": CharacterTextSplitter,\n",
        "}\n",
        "\n",
        "# Load documents (pdf files converted to text files)\n",
        "def load_text_documents(directory):\n",
        "    documents = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            with open(filepath, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "                documents.append(Document(page_content=content))\n",
        "    return documents\n",
        "\n",
        "# Load documents\n",
        "documents = load_text_documents(papers_directory)\n",
        "\n",
        "# Evaluate each splitter with different chunk_overlap values\n",
        "evaluation_results = {}\n",
        "for name, splitter_cls in splitters.items():\n",
        "    for overlap in chunk_overlap_values:\n",
        "        splitter = splitter_cls(chunk_size=500, chunk_overlap=overlap)  # keep chunk size constant and vary overlap\n",
        "        result = evaluate_splitter(documents, splitter)\n",
        "        evaluation_results[(name, overlap)] = result\n",
        "        print(f\"Evaluating Splitter: {name}, Chunk Overlap: {overlap}\")\n",
        "        print(f\"Number of Chunks: {len([Document(page_content=chunk) for document in documents for chunk in splitter.split_text(document.page_content)])}\")\n",
        "        print(f\"Average Chunk Size: {result}\")\n",
        "        print(f\"Evaluation Time: {evaluate_splitter(documents, splitter, metric='eval_time'):.2f} seconds\\n\")\n",
        "\n",
        "# Select the best splitter and chunk_overlap based on the metric\n",
        "best_splitter_name, best_overlap = min(evaluation_results, key=evaluation_results.get)\n",
        "best_splitter = splitters[best_splitter_name](chunk_size=500, chunk_overlap=best_overlap)\n",
        "print(f\"Best Splitter: {best_splitter_name} with Chunk Overlap: {best_overlap} and Average Chunk Size: {evaluation_results[(best_splitter_name, best_overlap)]}\\n\")\n",
        "\n",
        "# Print the chosen configuration\n",
        "print(\"Chosen Configuration:\")\n",
        "print(f\"Splitter: {best_splitter_name}\")\n",
        "print(f\"Chunk Overlap: {best_overlap}\")\n",
        "print(f\"Metric Value (Average Chunk Size): {evaluation_results[(best_splitter_name, best_overlap)]}\")\n",
        "\n",
        "# Use the best splitter to split the documents\n",
        "chunks = [Document(page_content=chunk) for document in documents for chunk in best_splitter.split_text(document.page_content)]\n",
        "\n",
        "print(\"\\nDocument chunks created using the best splitter and chunk overlap configuration.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D87NVJSxjTdx",
        "outputId": "c03bbf91-da94-4fbc-f15d-edeea48884d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Splitter: RecursiveCharacterTextSplitter, Chunk Overlap: 0\n",
            "Number of Chunks: 4240\n",
            "Average Chunk Size: 455.62594339622643\n",
            "Evaluation Time: 0.17 seconds\n",
            "\n",
            "Evaluating Splitter: RecursiveCharacterTextSplitter, Chunk Overlap: 10\n",
            "Number of Chunks: 4243\n",
            "Average Chunk Size: 455.7977845863776\n",
            "Evaluation Time: 0.12 seconds\n",
            "\n",
            "Evaluating Splitter: RecursiveCharacterTextSplitter, Chunk Overlap: 25\n",
            "Number of Chunks: 4259\n",
            "Average Chunk Size: 455.41629490490726\n",
            "Evaluation Time: 0.24 seconds\n",
            "\n",
            "Evaluating Splitter: RecursiveCharacterTextSplitter, Chunk Overlap: 50\n",
            "Number of Chunks: 4301\n",
            "Average Chunk Size: 456.0823064403627\n",
            "Evaluation Time: 0.10 seconds\n",
            "\n",
            "Evaluating Splitter: RecursiveCharacterTextSplitter, Chunk Overlap: 100\n",
            "Number of Chunks: 4731\n",
            "Average Chunk Size: 456.2441344324667\n",
            "Evaluation Time: 0.30 seconds\n",
            "\n",
            "Evaluating Splitter: CharacterTextSplitter, Chunk Overlap: 0\n",
            "Number of Chunks: 40\n",
            "Average Chunk Size: 48401.325\n",
            "Evaluation Time: 0.00 seconds\n",
            "\n",
            "Evaluating Splitter: CharacterTextSplitter, Chunk Overlap: 10\n",
            "Number of Chunks: 40\n",
            "Average Chunk Size: 48401.325\n",
            "Evaluation Time: 0.00 seconds\n",
            "\n",
            "Evaluating Splitter: CharacterTextSplitter, Chunk Overlap: 25\n",
            "Number of Chunks: 40\n",
            "Average Chunk Size: 48401.325\n",
            "Evaluation Time: 0.00 seconds\n",
            "\n",
            "Evaluating Splitter: CharacterTextSplitter, Chunk Overlap: 50\n",
            "Number of Chunks: 40\n",
            "Average Chunk Size: 48401.325\n",
            "Evaluation Time: 0.00 seconds\n",
            "\n",
            "Evaluating Splitter: CharacterTextSplitter, Chunk Overlap: 100\n",
            "Number of Chunks: 40\n",
            "Average Chunk Size: 48401.325\n",
            "Evaluation Time: 0.00 seconds\n",
            "\n",
            "Best Splitter: RecursiveCharacterTextSplitter with Chunk Overlap: 25 and Average Chunk Size: 455.41629490490726\n",
            "\n",
            "Chosen Configuration:\n",
            "Splitter: RecursiveCharacterTextSplitter\n",
            "Chunk Overlap: 25\n",
            "Metric Value (Average Chunk Size): 455.41629490490726\n",
            "\n",
            "Document chunks created using the best splitter and chunk overlap configuration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# local file store to cache embeddings\n",
        "store = LocalFileStore(\"./cache/\")\n",
        "\n",
        "# Instantiate the OpenAI core embeddings model\n",
        "core_embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "# Create a CacheBackedEmbeddings object from the core embeddings model\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    core_embeddings_model,\n",
        "    store,\n",
        "    namespace = core_embeddings_model.model\n",
        ")\n",
        "\n",
        "# Create a vector store using FAISS from document chunks\n",
        "vectorstore = FAISS.from_documents(chunks, embedder)\n",
        "\n",
        "# Instantiate a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "print(\"Setup complete, vector store and retriever are ready for use.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_WKZWvzQLH7",
        "outputId": "a2315ea7-3351-4968-989c-daf31a088578"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete, vector store and retriever are ready for use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the LLM using ChatOpenAI with the specified model\n",
        "llm = ChatOpenAI(temperature=0.2, model_name='gpt-3.5-turbo', max_tokens=4096)  # max_tokens is set to None by default (gpt-3.5-turbo has a capacity of 4096 tokens)\n",
        "\n",
        "# Setup memory for conversation history\n",
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, input_key='question', output_key='answer')\n",
        "\n",
        "# Setup the StdOutCallbackHandler to print outputs directly\n",
        "handler = StdOutCallbackHandler()\n",
        "\n",
        "# Setup the ConversationalRetrievalChain\n",
        "qachat = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    retriever=retriever,\n",
        "    callbacks=[handler],\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "print(\"Conversational Retrieval Chain setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn8T9eSIQOR5",
        "outputId": "6864132e-7507-44a8-eb93-ef3eda9b3680"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversational Retrieval Chain setup complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Context manager to suppress stdout from qachat (ConversationalRetrievalChain)\n",
        "@contextlib.contextmanager\n",
        "def suppress_stdout():\n",
        "    with StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "        yield\n",
        "\n",
        "# Function to process queries through the QA chain\n",
        "def ask_question(question):\n",
        "    with suppress_stdout():\n",
        "        response = qachat({\"question\": question})\n",
        "    return response['answer']\n",
        "\n",
        "# Function to format and print the response with wrapping\n",
        "def format_response(text, width=80):\n",
        "    wrapper = textwrap.TextWrapper(width=width)\n",
        "    wrapped_text = wrapper.fill(text)\n",
        "    return wrapped_text\n",
        "\n",
        "# Create a Textarea widget for larger input\n",
        "textarea = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Type your question here...',\n",
        "    description='',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='60%', height='80px', border='none', margin='20px 0 0 0')\n",
        ")\n",
        "\n",
        "# Create a button to submit the query\n",
        "button = widgets.Button(\n",
        "    description=\"Submit\",\n",
        "    layout=widgets.Layout(margin='60px 0 0 20px', width='70px', height='40px')\n",
        ")\n",
        "\n",
        "# Create an output widget test box to display the response\n",
        "response_output = widgets.Output()\n",
        "\n",
        "# Function to handle button click event (for submit)\n",
        "def on_button_click(b):\n",
        "    user_query = textarea.value\n",
        "    result = ask_question(user_query)\n",
        "    formatted_result = format_response(result)\n",
        "\n",
        "    with response_output:\n",
        "        response_output.clear_output()\n",
        "\n",
        "        # Display formatted result\n",
        "        display(HTML(f\"<div style='border:1px solid #ddd; padding:15px; border-radius:10px; background-color:#f9f9f9; width:58%; margin-top:20px;'>{formatted_result}</div>\"))\n",
        "\n",
        "# Attach the button click event handler\n",
        "button.on_click(on_button_click)\n",
        "\n",
        "# Styled container for question input\n",
        "textarea_styled = widgets.HTML(\n",
        "    value=\"\"\"\n",
        "    <style>\n",
        "        .styled-container {\n",
        "            border: 1px solid #ddd;\n",
        "            padding: 15px;\n",
        "            border-radius: 10px;\n",
        "            background-color: #f9f9f9;\n",
        "            width: 30%;\n",
        "            margin-top: 10px;\n",
        "            font-family: sans-serif, sans-serif;\n",
        "            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n",
        "        }\n",
        "        .styled-container h3 {\n",
        "            font-weight: bold;\n",
        "            margin-bottom: 8px;\n",
        "        }\n",
        "        .styled-container p {\n",
        "            margin-bottom: 10px;\n",
        "        }\n",
        "        .styled-container textarea {\n",
        "            width: 100%;\n",
        "            height: 80px;\n",
        "            padding: 10px;\n",
        "            border-radius: 5px;\n",
        "            border: 1px solid #ccc;\n",
        "            font-family: sans-serif, sans-serif;\n",
        "            font-size: 14px;\n",
        "        }\n",
        "    </style>\n",
        "    <div class='styled-container'>\n",
        "        <h3>RAG Model for Jamming Source Localization</h3>\n",
        "        <p>Ask a question related to research on jamming source localization.</p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Container for input and button\n",
        "input_container = widgets.HBox([textarea, button], layout=widgets.Layout(align_items='flex-start', margin='10px 0 0 0'))\n",
        "\n",
        "# Display the styled container, Textarea, button, and response\n",
        "display(widgets.VBox([\n",
        "    textarea_styled,\n",
        "    input_container,\n",
        "    response_output\n",
        "]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366,
          "referenced_widgets": [
            "49dec511f7674f5791e96f6749128911",
            "52f66ae24d75476caec540dfdc5db7e6",
            "d1fe580451094fd892a05def982fd343",
            "1096b83d9e014d91bc63025cb32b92f6",
            "db02187f86054e34a6cbc06f10cd64b0",
            "2937ea6581804370a5cc8b7ed41aab69",
            "41a66c78de7f4070956888fd42cd564f",
            "8be5b1fd7aa749589dff275017a2c99c",
            "1d1a93f6f8d54335b1a7423f9fa48e5a",
            "4dabeb12d3b34e8fa6124f00d7d4460b",
            "ce3d8499c97a4454964a4ed7ae0721ea",
            "5c4442eafc6d4c5080e8711176172c8c",
            "fcf02bf0303c42adafa337a18e355e65",
            "3f2e9199dc854b4ba90f7976b0792aac",
            "5cee3e138b254f108bf29abb6adc2357"
          ]
        },
        "id": "JpG-Wu4jVFWq",
        "outputId": "7461e034-724a-4052-e3d4-6b15a5110198"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value=\"\\n    <style>\\n        .styled-container {\\n            border: 1px solid #ddd;\\n  …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49dec511f7674f5791e96f6749128911"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example inputs:\n",
        "- What's the latest research on jamming source localization?\n",
        "- What input data is used by the jamming source localization models?\n",
        "- Can you name some methods used in jamming source localization research?\n",
        "- Are there any jamming source localization papers that frame their problem statement in 3D space or do they just use 2D?\n",
        "- If I have a swarm of drones in 3D space and I want to employ a jamming source localization method, can you name a few that might be relevant?\n",
        "- Please list the most recently published research papers on jamming source localization.\n",
        "- Provide a list of jamming source localization research papers that use GPS and received signal strength data to localize the jammer."
      ],
      "metadata": {
        "id": "cIZSjfjSTFbf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49dec511f7674f5791e96f6749128911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52f66ae24d75476caec540dfdc5db7e6",
              "IPY_MODEL_d1fe580451094fd892a05def982fd343",
              "IPY_MODEL_1096b83d9e014d91bc63025cb32b92f6"
            ],
            "layout": "IPY_MODEL_db02187f86054e34a6cbc06f10cd64b0"
          }
        },
        "52f66ae24d75476caec540dfdc5db7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2937ea6581804370a5cc8b7ed41aab69",
            "placeholder": "​",
            "style": "IPY_MODEL_41a66c78de7f4070956888fd42cd564f",
            "value": "\n    <style>\n        .styled-container {\n            border: 1px solid #ddd;\n            padding: 15px;\n            border-radius: 10px;\n            background-color: #f9f9f9;\n            width: 30%;\n            margin-top: 10px;\n            font-family: sans-serif, sans-serif;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n        .styled-container h3 {\n            font-weight: bold;\n            margin-bottom: 8px;\n        }\n        .styled-container p {\n            margin-bottom: 10px;\n        }\n        .styled-container textarea {\n            width: 100%;\n            height: 80px;\n            padding: 10px;\n            border-radius: 5px;\n            border: 1px solid #ccc;\n            font-family: sans-serif, sans-serif;\n            font-size: 14px;\n        }\n    </style>\n    <div class='styled-container'>\n        <h3>RAG Model for Jamming Source Localization</h3>\n        <p>Ask a question related to research on jamming source localization.</p>\n    </div>\n    "
          }
        },
        "d1fe580451094fd892a05def982fd343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8be5b1fd7aa749589dff275017a2c99c",
              "IPY_MODEL_1d1a93f6f8d54335b1a7423f9fa48e5a"
            ],
            "layout": "IPY_MODEL_4dabeb12d3b34e8fa6124f00d7d4460b"
          }
        },
        "1096b83d9e014d91bc63025cb32b92f6": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_5cee3e138b254f108bf29abb6adc2357",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<div style='border:1px solid #ddd; padding:15px; border-radius:10px; background-color:#f9f9f9; width:58%; margin-top:20px;'>The latest research on jamming source localization involves methods that utilize\nnetwork topology changes caused by jamming attacks to estimate the jammer's\nposition. Some recent approaches include measuring Packet Delivery Ratio (PDR)\nand performing a gradient descent search, as well as using virtual forces\nderived from network topology changes. These methods require iterative searches\nand aim to precisely determine the position of jammers in wireless sensor\nnetworks.</div>"
                },
                "metadata": {}
              }
            ]
          }
        },
        "db02187f86054e34a6cbc06f10cd64b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2937ea6581804370a5cc8b7ed41aab69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a66c78de7f4070956888fd42cd564f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8be5b1fd7aa749589dff275017a2c99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ce3d8499c97a4454964a4ed7ae0721ea",
            "placeholder": "Type your question here...",
            "rows": null,
            "style": "IPY_MODEL_5c4442eafc6d4c5080e8711176172c8c",
            "value": "What's the latest research on jamming source localization?"
          }
        },
        "1d1a93f6f8d54335b1a7423f9fa48e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_fcf02bf0303c42adafa337a18e355e65",
            "style": "IPY_MODEL_3f2e9199dc854b4ba90f7976b0792aac",
            "tooltip": ""
          }
        },
        "4dabeb12d3b34e8fa6124f00d7d4460b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "flex-start",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "10px 0 0 0",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3d8499c97a4454964a4ed7ae0721ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "none",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "80px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "20px 0 0 0",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "60%"
          }
        },
        "5c4442eafc6d4c5080e8711176172c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcf02bf0303c42adafa337a18e355e65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "40px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "60px 0 0 20px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "70px"
          }
        },
        "3f2e9199dc854b4ba90f7976b0792aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5cee3e138b254f108bf29abb6adc2357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}